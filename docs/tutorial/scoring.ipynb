{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    ".. _scoring_tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make imports\n",
    "import opcsim\n",
    "import numpy as np\n",
    "\n",
    "# turn off warnings temporarily\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluating the Results of a Simulated OPC \n",
    "\n",
    "To determine the efficacy of our simulated OPC's, we must derive some sort of metric to use to compare to other modeled OPC's and other distributions. Perusing through the current literature, you will find two primary methods that encapsulate how this is done.\n",
    "\n",
    "## 1. Number-Volume Correlation Method (`opcsim.metrics.nv_score`)\n",
    "  \n",
    "The number-correlation method is used throughout the low-cost sensor community, especially since it is quite often the only option. Essentially, you simply correlate the output variable of the OPC (typically something related to number concentration) to PM2.5 (or other Mass loading) from a reference instrument. \n",
    "      \n",
    "In doing so, you are inherently assuming the underlying particle distribution does not vary too much from whatever distribution you calibrated against. To calculate the number-volume correlation, we use the following relationship: \n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{N}{V}=\\frac{Number\\;of\\;particles\\;seen\\;by\\;the\\;OPC}{total\\;integrated\\;volume\\;in\\;the\\;underlying\\;distribution}$$\n",
    "  \n",
    "\n",
    "To compute this value, we can use the `opcsim.metrics.nv_score` function which requires just the `opcsim.OPC` model and the `opcsim.AerosolDistribution`. Optionally, you can limit the minimum and maximum diameters to evaluate the volume CDF under; however, this will not change the number calculation from the OPC.\n",
    "\n",
    "For example, let's compute the `nv_score` for the 1-bin OPC that is default against the urban distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build the OPC\n",
    "opc = opcsim.OPC()\n",
    "\n",
    "# load the distribution\n",
    "urban = opcsim.load_distribution(\"Urban\")\n",
    "\n",
    "# compute the nv_score\n",
    "opcsim.metrics.nv_score(opc, urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the meaning of this number? Nothing, really. On it's own, this value is pretty useless. It is the slope between the number of particles your OPC \"sees\" and the total volume under 2.5 microns in the urban distribution. Now, if we change the distribution, what happens? Let's try computing the same score for the rural distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural = opcsim.load_distribution(\"Rural\")\n",
    "\n",
    "opcsim.metrics.nv_score(opc, rural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh! Nearly a 30% difference just by slightly perturbing the underlying particle size distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Volume-Volume Correlation Method (`opcsim.metrics.vv_score`)\n",
    "\n",
    "The volume-correlation method is used by some of the more robust low-cost OPCs (like the Alphasense OPC-N2) which have many size bins. The idea behind the volume method is to actually do a step-wise integration across the bins to calculate the total volume/mass present. Unfortunately, most of these sensors still have relatively high $dmin$ values which means they are blind to a large enough fraction of the mass that it makes a difference.\n",
    "\n",
    "Unlike the number-correlation method described above, this method has a chance at observing changes in the underlying size distribution. To score this method, we take the ratio of the total volume calculated across the bins of the OPC to the total volume present in the underlying particle size distribution.\n",
    "\n",
    "To compute this value, we can use the `opcsim.metrics.vv_score` function which requires just the `opcsim.OPC` model and the `opcsim.AerosolDistribution`. Optionally, you can limit the minimum and maximum diameters to evaluate the volume CDF under; however, this will not change the volume calculation from the OPC.\n",
    "\n",
    "For example, let's compute the `vv_score` for the 1-bin OPC that is default against the urban distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcsim.metrics.vv_score(opc, urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this value mean? Well, it is simply a ratio of OPC volume to Actual Volume, so this is the fraction of volume seen by the OPC.\n",
    "\n",
    "How much does it change when the distribution changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcsim.metrics.vv_score(opc, rural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these numbers look relatively great, it may just be a fluke! What happens when we score this method for a variety of different OPCs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "dmin = 0.3\n",
    "dmax = 2.5\n",
    "\n",
    "for i in range(1, 10):\n",
    "    models.append((\"{}-Bin OPC\".format(i), opcsim.OPC(n_bins=i, dmin=dmin, dmax=dmax)))\n",
    "\n",
    "for model in models:\n",
    "    nv = opcsim.metrics.nv_score(model[1], urban)\n",
    "    vv = opcsim.metrics.vv_score(model[1], urban)\n",
    "    \n",
    "    print (\"\\n{}\".format(model[0]))\n",
    "    print (\"\\tN/V = {:.3f}\".format(nv))\n",
    "    print (\"\\tV/V = {:.3f}\".format(vv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number correlation method stayed the same for all OPCs! Why? Well, right now we have simulated each of these with a counting efficiency of 1 which means they see 100% of the particles. While this doesn't change the number of particles we see in total, it does change the volume!\n",
    "\n",
    "This ends the introduction to using the metrics to score your OPC/Distribution model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
